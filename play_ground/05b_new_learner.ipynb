{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from uti.basic_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.fastai/data/mnist.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "train_ds,valid_ds = get_dataset(*get_data())\n",
    "data = Databunch(*get_dl(train_ds,valid_ds,bs=64),c=10)\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove callback_handler \n",
    "\n",
    "Bringing everything inside learner. Start to have different code as Jeremy in fastai notebook\n",
    "\n",
    "1. _set_learner\n",
    "when callback created, it needs leaner information, such as model,opt...etc\n",
    "which is only available when learner is created\n",
    "\n",
    "However, leaner needs to add callbacks when Leaner is created\n",
    "\n",
    "Previously we use callback_handler to act as intermediate interface to pass the values. \n",
    "But this can be done inside the Leaner, just do cb._set_learner(self) in fit loop\n",
    "\n",
    "When inside fit loop, we have all the states ready, such as model, opt, epochs...\n",
    "calling set_learner(self) inside fit will just pass Leaner itself into callbacks \n",
    "\n",
    "The set_learner here acts like constructor but it will only be triggered during run time. \n",
    "\n",
    "Pure software engineering, not ML involved \n",
    "\n",
    "But this way, we will have a very easy interface to use\n",
    "\n",
    "2. Diff from Jeremy's code\n",
    "I still kept Callback methods, which I think it is easier to have abstract class ready for later use (and possible maintance in the future)\n",
    "\n",
    "I didn't use __getattr__ , explictly calling method name makes things clear, which attribute is from leaner, which is from callback itself\n",
    "\n",
    "The rest of the ideas are the same as fastai 2019 part2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#abstract class for new callback\n",
    "class Callback():\n",
    "    _order = 0\n",
    "    def _set_learner(self,learn): self.learn = learn\n",
    "    def begin_fit(self): pass\n",
    "    def after_fit(self): pass\n",
    "    def begin_epoch(self): pass\n",
    "    def begin_validate(self): pass\n",
    "    def after_epoch(self): pass\n",
    "    def begin_batch(self): pass\n",
    "    def after_batch(self): pass\n",
    "    def after_loss(self): pass\n",
    "    def begin_backward(self): pass\n",
    "    def after_backward(self): pass\n",
    "    def after_step(self): pass\n",
    "    def after_cancel_train(self): pass   \n",
    "    def after_cancel_epoch(self): pass\n",
    "    def after_cancel_batch(self): pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.n_epochs, self.n_iters = 0,0\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.n_epochs = self.learn.epoch #current epoch\n",
    "        self.learn.model.train()\n",
    "        self.learn.in_train = True\n",
    "        \n",
    "    def after_batch(self):\n",
    "        if not self.learn.in_train: return\n",
    "        self.n_epochs += 1. / self.learn.iters #current epoch step, eg: 1.3 epochs\n",
    "        self.n_iters +=1\n",
    "        \n",
    "    def begin_validate(self):\n",
    "        self.learn.model.eval()\n",
    "        self.learn.in_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NewLearner():\n",
    "    def __init__(self, model,opt,loss_func,data,cbs=None):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data\n",
    "        self.in_train = False\n",
    "        self.cbs = []\n",
    "        self.cbs.append(TrainEvalCallback())\n",
    "        if cbs:\n",
    "            for cb in sorted(cbs,key = lambda x: x._order):\n",
    "                self.cbs.append(cb)\n",
    "        \n",
    "    def one_batch(self,xb,yb):\n",
    "        try: \n",
    "            self.xb, self.yb = xb, yb\n",
    "            for cb in self.cbs: cb.begin_batch()\n",
    "            self.preds = self.model(self.xb)\n",
    "            self.loss = self.loss_func(self.preds,self.yb)\n",
    "            for cb in self.cbs: cb.after_loss()\n",
    "            \n",
    "            if not self.in_train: return\n",
    "            \n",
    "            for cb in self.cbs: cb.begin_backward()\n",
    "            self.loss.backward()\n",
    "            for cb in self.cbs: cb.after_backward()\n",
    "            self.opt.step()\n",
    "            for cb in self.cbs: cb.after_step()\n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "        except CancelBatchException: \n",
    "            for cb in self.cbs: cb.after_cancel_batch()\n",
    "        \n",
    "        finally:\n",
    "            for cb in self.cbs: cb.after_batch()\n",
    "\n",
    "    def all_batches(self):\n",
    "        try:\n",
    "            for xb,yb in self.dl:\n",
    "                self.one_batch(xb,yb)\n",
    "        except CancelEpochException: \n",
    "            for cb in self.cbs: cb.after_cancel_epoch()\n",
    "\n",
    "\n",
    "    def fit(self,epochs):\n",
    "        self.epochs = epochs\n",
    "        self.iters = len(self.data.train_dl)\n",
    "        try:\n",
    "            for cb in self.cbs: cb._set_learner(self)\n",
    "            for cb in self.cbs: cb.begin_fit()\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                self.dl = self.data.train_dl\n",
    "                for cb in self.cbs: cb.begin_epoch()\n",
    "                self.all_batches()\n",
    "        \n",
    "                for cb in self.cbs: cb.begin_validate()\n",
    "                self.dl = self.data.valid_dl\n",
    "                with torch.no_grad(): self.all_batches()\n",
    "                for cb in self.cbs: cb.after_epoch()\n",
    "                \n",
    "        except CancelTrainException: \n",
    "            for cb in self.cbs: cb.after_cancel_train()\n",
    "                \n",
    "        finally:\n",
    "            for cb in self.cbs: cb.after_fit()\n",
    "            #self.remove(cb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = NewLearner(*get_model(data),loss_func,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999903"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.cbs[0].n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Accuracy(Callback):\n",
    "    def begin_epoch(self):\n",
    "        self.train_loss, self.valid_loss = 0, 0\n",
    "        self.train_acc, self.valid_acc =0, 0\n",
    "        self.train_bs_count = 0\n",
    "        self.valid_bs_count = 0\n",
    "        \n",
    "    def accuracy(self, out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        with torch.no_grad():\n",
    "            bs = self.learn.xb.shape[0]\n",
    "            if self.learn.in_train: \n",
    "                self.train_loss += self.learn.loss * bs\n",
    "                self.train_acc += self.accuracy(self.learn.preds,self.learn.yb) * bs\n",
    "                self.train_bs_count += bs\n",
    "            else: \n",
    "                self.valid_loss += self.learn.loss * bs\n",
    "                self.valid_acc += self.accuracy(self.learn.preds,self.learn.yb) * bs\n",
    "                self.valid_bs_count += bs\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        avg_train_loss = self.train_loss / self.train_bs_count\n",
    "        avg_valid_loss = self.valid_loss / self.valid_bs_count\n",
    "        avg_train_acc = self.train_acc / self.train_bs_count\n",
    "        avg_valid_acc = self.valid_acc / self.valid_bs_count\n",
    "        print(f'Train: {avg_train_loss}, {avg_train_acc}')\n",
    "        print(f'Valid: {avg_valid_loss}, {avg_valid_acc}')\n",
    "        print(' ')\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = NewLearner(*get_model(data),loss_func,data,cbs=[Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.3097740709781647, 0.904699981212616\n",
      "Valid: 0.4988924264907837, 0.8432999849319458\n",
      " \n",
      "Train: 0.14133064448833466, 0.9574400186538696\n",
      "Valid: 0.12808431684970856, 0.9609000086784363\n",
      " \n",
      "Train: 0.10768666118383408, 0.9674400091171265\n",
      "Valid: 0.10633409768342972, 0.9696999788284302\n",
      " \n"
     ]
    }
   ],
   "source": [
    "learn.fit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook2script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 05b_new_learner.ipynb to uti/newLeaner_05b.py\n"
     ]
    }
   ],
   "source": [
    "notebook2script('05b_new_learner.ipynb','newLeaner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
